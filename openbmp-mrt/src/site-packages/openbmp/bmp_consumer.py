# -*- coding: utf-8 -*-
"""OpenBMP MRT

  Copyright (c) 2013-2016 Cisco Systems, Inc. and others.  All rights reserved.
  This program and the accompanying materials are made available under the
  terms of the Eclipse Public License v1.0 which accompanies this distribution,
  and is available at http://www.eclipse.org/legal/epl-v10.html

  .. moduleauthor:: Tim Evens <tievens@cisco.com>
"""
import multiprocessing
import socket
import kafka
import kafka.common
import time


from openbmp.mrt_bgp4mp_object import MrtBgpMpObject
from openbmp.logger import init_mp_logger
from openbmp.parsed.headers import headers as parsed_headers
from openbmp.parsed.collector import collector
from openbmp.parsed.router import router
from openbmp.parsed.peer import peer
from openbmp.bmp import bmp_parse_bmphdr, bmp_parse_peerhdr



class BMPConsumer(multiprocessing.Process):
    """ OpenBMP consumer

        Consumes openbmp.parsed.collector, openbmp.parsed.router, and openbmp.bmp_raw
        message feeds from Kafka.  Collector and router messages are cached.
    """
    # Memory cache of collectors
    COLLECTORS = {}

    # Memory cache of routers
    ROUTERS = {}

    # Memory cache of peers
    PEERS = {}

    def __init__(self, cfg, mrt_bgp4mp_queue, log_queue):
        """ Constructor

            :param cfg:               Configuration dictionary
            :param mrt_bgp4mp_queue:  Output for MRT BGP4MP type
            :param log_queue:         Logging queue - sync logging
        """
        multiprocessing.Process.__init__(self)
        self._stop = multiprocessing.Event()

        self._cfg = cfg
        self._bgp4mp_queue = mrt_bgp4mp_queue
        self._log_queue = log_queue
        self.LOG = None

    def run(self):
        """ Override """
        self.LOG = init_mp_logger("bmp_consumer", self._log_queue)

        # Enable to topics/feeds
        topics = ['openbmp.parsed.collector', 'openbmp.parsed.router', 'openbmp.parsed.peer', 'openbmp.bmp_raw']

        self.LOG.info("Running bmp_consumer")

        # wait for config to load
        while not self.stopped():
            if self._cfg and 'kafka' in self._cfg:
                break


        try:
            # connect and bind to topics
            self.LOG.info("Connecting to %s ... takes a minute to load offsets and topics, please wait" % self._cfg['kafka']['servers'])
            consumer = kafka.KafkaConsumer(*topics,
                                           bootstrap_servers=self._cfg['kafka']['servers'],
                                           client_id=self._cfg['kafka']['client_id'] + '-' + socket.gethostname(),
                                           socket_timeout_ms=5000,
                                           fetch_message_max_bytes=5000000,
                                           group_id=self._cfg['kafka']['group_id'],
                                           auto_commit_enable=True,
                                           auto_commit_interval_ms=1000,
                                           auto_offset_reset='largest' if
                                                            self._cfg['kafka']['offset_reset_largest'] else "smallest")

            self.LOG.info("Connected, now consuming")

            prev_ts = time.time()

            # Loop till stopped
            while not self.stopped():

                # Read messages
                for m in consumer.fetch_messages():
                    if self.stopped():
                        break

                    self.process_msg(m)
                    consumer.task_done(m)

        except kafka.common.KafkaUnavailableError as err:
            self.LOG.error("Kafka Error: %s" % str(err))

        except KeyboardInterrupt:
            pass

        self.LOG.info("consumer stopped")

    def stop(self):
        self._stop.set()

    def stopped(self):
        return self._stop.is_set()

    def process_msg(self, msg):
        """ Process the message

        :param msg:     Message consumed
        """
        (headers, data) = msg.value.split("\n\n", 1)

        hdr = parsed_headers()
        hdr.parse(headers)

        if msg.topic == 'openbmp.parsed.collector':
            self.process_collector_msg(hdr.getCollectorHashId(), data)

        elif msg.topic == 'openbmp.parsed.router':
            self.process_router_msg(hdr.getCollectorHashId(), data)

        elif msg.topic == 'openbmp.parsed.peer':
            self.process_peer_msg(hdr.getCollectorHashId(), data)

        elif msg.topic == 'openbmp.bmp_raw':
            self.process_bmp_raw_msg(hdr.getCollectorHashId(),
                                     hdr.getRouterHashId(), hdr.getRouterIp(), data)

    def process_collector_msg(self, c_hash, data):
        """ Process collector message and cache info for use later

            :param c_hash:      Collector Hash ID
            :param data:        Message data to be consumed (should not contain headers)
        """
        obj = collector()

        for row in data.split('\n'):
            if len(row):
                try:
                    obj.parse(row)

                    self.LOG.debug("collector: %s [%s]", obj.getAdminId(), obj.getAction())

                    if obj.getAction() in ('started', 'heartbeat', 'change'):

                        # Update collector hash/cache
                        if obj.getHashId() not in self.COLLECTORS:
                            self.COLLECTORS[obj.getHashId()] = {'admin_id': obj.getAdminId()}

                    else:
                        self.COLLECTORS.pop(obj.getHashId(), None)

                except:
                    pass

    def process_router_msg(self, c_hash, data):
        """ Process Router message

            :param c_hash:      Collector Hash ID
            :param data:        Message data to be consumed (should not contain headers)
        """
        obj = router()

        # Log messages
        for row in data.split('\n'):
            if len(row):
                try:
                    obj.parse(row)

                    self.LOG.info("router: [%s] %s %s", obj.getAction(),
                                   obj.getName(), obj.getIpAddress())

                    if obj.getAction() in ('first', 'init'):
                        # Update the router hash/cache
                        if obj.getHashId() not in self.ROUTERS:
                            self.ROUTERS[obj.getHashId()] = {'ip': obj.getRouterIp(),
                                                              'name': obj.getName()}
                    # else:
                    #     self.ROUTERS.pop(obj.getHashId(), None)

                except:
                    self.LOG.debug("router parse error")
                    pass

    def process_peer_msg(self, c_hash, data):
        """ Process Peer message

            :param c_hash:      Collector Hash ID
            :param data:        Message data to be consumed (should not contain headers)
        """
        obj = peer()

        # Log messages
        for row in data.split('\n'):
            if len(row):
                try:
                    obj.parse(row)

                    peer_key = obj.getRouterHashId() + '_' + obj.getRemoteBgpId() + '_' + str(obj.getPeerRd())

                    self.LOG.info("peer: [%s] %s %s", obj.getAction(),
                                   obj.getName(), obj.getIpAddress())

                    if obj.getAction() in ('up'):

                        asn_len = 2
                        if ('4 Octet ASN' in obj.getAdvCapabilities() and
                            '4 Octet ASN' in obj.getRecvCapabilities()):
                            asn_len = 4

                        # Update the peer hash/cache
                        if obj.getHashId() not in self.PEERS:
                            self.PEERS[peer_key] = {'remote_ip': obj.getRemoteIp(),
                                                    'remote_asn': obj.getRemoteAsn(),
                                                    'local_ip': obj.getLocalIp(),
                                                    'local_asn': obj.getLocalAsn(),
                                                    'asn_len': asn_len,
                                                    'rd': obj.getPeerRd()}
                except:
                    self.LOG.debug("peer parse error")
                    pass

    def process_bmp_raw_msg(self, c_hash, r_hash, r_ip, data):
        """ Process BMP RAW message

        :param c_hash:      Collector Hash ID
        :param r_hash:      Router Hash ID
        :param r_ip:        Router IP address
        :param data:        Message data to be consumed (should not contain headers)
        """
        msg = MrtBgpMpObject()

        msg.COLLECTOR_HASH_ID = c_hash
        msg.ROUTER_IP = r_ip

        msg.PEER_KEY = ""

        # Parse the BMP header
        bmp_hdrs = bmp_parse_bmphdr(data)

        # Parse the BMP headers
        if bmp_hdrs['type'] in ('ROUTE_MON'):
            peer_hdr = bmp_parse_peerhdr(data[6:])
            msg.BMP_DATA = data[48:]

            msg.PEER_ADDR = peer_hdr['addr']
            msg.PEER_RD = peer_hdr['dist_id']
            msg.PEER_ASN = peer_hdr['asn']
            msg.PEER_BGP_ID = peer_hdr['bgp_id']

            if long(peer_hdr['ts_secs']) == 0:
                msg.TIMESTAMP_SEC = time.time()
            else:
                msg.TIMESTAMP_SEC = peer_hdr['ts_secs']

            msg.TIMESTAMP_USEC = peer_hdr['ts_usecs']

            msg.PEER_KEY = r_hash + '_' + msg.PEER_BGP_ID + '_' + str(msg.PEER_RD)

            if c_hash in self.COLLECTORS:
                msg.COLLECTOR_ADMIN_ID = self.COLLECTORS[c_hash]['admin_id']

            if r_hash in self.ROUTERS:
                msg.ROUTER_NAME = self.ROUTERS[r_hash]['name']

            if msg.PEER_KEY in self.PEERS:
                msg.LOCAL_ADDR = self.PEERS[msg.PEER_KEY]['local_ip']
                msg.LOCAL_ASN = self.PEERS[msg.PEER_KEY]['local_asn']
                msg.PEER_ASN_LENGTH = self.PEERS[msg.PEER_KEY]['asn_len']

            # queue message
            self._bgp4mp_queue.put(msg)

        else:
            self.LOG.debug("BMP message type %r not used" % bmp_hdrs['type'])
